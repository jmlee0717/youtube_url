import streamlit as st
import os
import json
import requests
from datetime import datetime, timedelta
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import gspread
from google.oauth2.service_account import Credentials
import pandas as pd
import pickle

# ìƒíƒœ ì €ì¥ íŒŒì¼ëª…
STATE_FILE = 'app_state.pkl'

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="YouTube to Sheets",
    page_icon="ğŸ“º",
    layout="wide"
)

# === Helper Functions ===

def save_state(state_data):
    """ìƒíƒœë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        with open(STATE_FILE, 'wb') as f:
            pickle.dump(state_data, f)
    except Exception as e:
        print(f"ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")

def load_state():
    """íŒŒì¼ì—ì„œ ìƒíƒœ ë¡œë“œ"""
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            print(f"ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return {}

# Session State ì´ˆê¸°í™” (ì‚¬ì´ë“œë°”ì—ì„œ ì ‘ê·¼í•˜ê¸° ìœ„í•´ ìƒë‹¨ìœ¼ë¡œ ì´ë™)
if 'search_results' not in st.session_state:
    # ì €ì¥ëœ ìƒíƒœ ë¡œë“œ ì‹œë„
    saved_state = load_state()
    if saved_state:
        st.session_state.update(saved_state)
    
    if 'search_results' not in st.session_state:
        st.session_state.search_results = pd.DataFrame()

    # ê¸°ì¡´ ë°ì´í„°ì— ìƒˆ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° í˜¸í™˜ì„± ì²˜ë¦¬
    if not st.session_state.search_results.empty:
        if 'view_sub_ratio' not in st.session_state.search_results.columns:
            st.session_state.search_results['view_sub_ratio'] = 0.0
        if 'view_diff' not in st.session_state.search_results.columns:
            st.session_state.search_results['view_diff'] = 0.0

def load_api_key():
    """api_key.txtì—ì„œ API í‚¤ ë¡œë“œ"""
    if os.path.exists('api_key.txt'):
        try:
            with open('api_key.txt', 'r', encoding='utf-8') as f:
                return f.read().strip()
        except:
            pass
    return ""

def get_credentials_files():
    """credentials í´ë”ì˜ JSON íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    creds_dir = os.path.join(os.getcwd(), 'credentials')
    if os.path.exists(creds_dir):
        return [f for f in os.listdir(creds_dir) if f.endswith('.json')]
    return []

def load_config_url():
    """config.txtì—ì„œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URL ë¡œë“œ"""
    config_path = 'config.txt'
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URL:"):
                        return line.split(":", 1)[1].strip()
        except Exception as e:
            print(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return ""



@st.cache_data(show_spinner=False)
def search_youtube(api_key, keyword, max_results, published_after=None, published_before=None):
    """YouTube API ê²€ìƒ‰ ìˆ˜í–‰"""
    try:
        youtube = build("youtube", "v3", developerKey=api_key)
        
        results = []
        next_page_token = None
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        while len(results) < max_results:
            status_text.text(f"ê²€ìƒ‰ ì¤‘... ({len(results)}/{max_results})")
            
            search_params = {
                'q': keyword,
                'part': "id,snippet",
                'maxResults': min(50, max_results - len(results)),
                'type': "video",
                'pageToken': next_page_token,
                'order': "relevance"
            }
            
            if published_after:
                search_params['publishedAfter'] = published_after
            if published_before:
                search_params['publishedBefore'] = published_before
                
            search_response = youtube.search().list(**search_params).execute()
            
            # ì±„ë„ ID ìˆ˜ì§‘
            channel_ids = []
            video_ids = []
            for item in search_response.get('items', []):
                channel_ids.append(item['snippet']['channelId'])
                video_ids.append(item['id']['videoId'])
            
            # ì±„ë„ ì •ë³´ ì¡°íšŒ (í†µê³„)
            channel_stats_map = {}
            if channel_ids:
                channels_response = youtube.channels().list(
                    part="statistics",
                    id=','.join(list(set(channel_ids))) # ì¤‘ë³µ ì œê±°
                ).execute()
                
                for channel in channels_response.get('items', []):
                    stats = channel['statistics']
                    channel_stats_map[channel['id']] = {
                        'subscriberCount': int(stats.get('subscriberCount', 0)),
                        'viewCount': int(stats.get('viewCount', 0)),
                        'videoCount': int(stats.get('videoCount', 0))
                    }

            if video_ids:
                videos_response = youtube.videos().list(
                    part="snippet,statistics,contentDetails",
                    id=','.join(video_ids)
                ).execute()
                
                for video in videos_response.get('items', []):
                    video_id = video['id']
                    snippet = video['snippet']
                    statistics = video.get('statistics', {})
                    channel_id = snippet.get('channelId')
                    
                    view_count = int(statistics.get('viewCount', 0))
                    comment_count = int(statistics.get('commentCount', 0))
                    
                    # ì±„ë„ í†µê³„ ê°€ì ¸ì˜¤ê¸°
                    ch_stats = channel_stats_map.get(channel_id, {'subscriberCount': 0, 'viewCount': 0, 'videoCount': 0})
                    subscriber_count = ch_stats['subscriberCount']
                    channel_total_views = ch_stats['viewCount']
                    channel_video_count = ch_stats['videoCount']
                    
                    # ì§€í‘œ 1: ì¡°íšŒìˆ˜ / êµ¬ë…ììˆ˜ ë¹„ìœ¨ (ì˜ìƒ ì¡°íšŒìˆ˜/êµ¬ë…)
                    view_sub_ratio = 0.0
                    if subscriber_count > 0:
                        view_sub_ratio = view_count / subscriber_count
                        
                    # ì§€í‘œ 2: ì¡°íšŒìˆ˜ - í‰ê· ì¡°íšŒìˆ˜
                    avg_views = 0
                    if channel_video_count > 0:
                        avg_views = channel_total_views / channel_video_count
                    view_diff = view_count - avg_views
                    
                    video_data = {
                        'selected': False, # ì²´í¬ë°•ìŠ¤ìš©
                        'thumbnail': snippet.get('thumbnails', {}).get('medium', {}).get('url', ''),
                        'url': f"https://youtube.com/watch?v={video_id}",
                        'title': snippet.get('title', ''),
                        'channel': snippet.get('channelTitle', ''),
                        'channel': snippet.get('channelTitle', ''),
                        'view_count': view_count,
                        'subscriber_count': subscriber_count, # ì¡°íšŒìˆ˜ì™€ ëŒ“ê¸€ìˆ˜ ì‚¬ì´ì— ë°°ì¹˜
                        'comment_count': comment_count,
                        'published_at': snippet.get('publishedAt', ''),
                        'view_sub_ratio': view_sub_ratio,
                        'view_diff': view_diff,
                        # 'subscriber_count': subscriber_count # (ì œê±°: ìœ„ë¡œ ì´ë™)
                    }
                    results.append(video_data)
            
            progress_bar.progress(min(len(results) / max_results, 1.0))
            
            next_page_token = search_response.get('nextPageToken')
            if not next_page_token:
                break
                
        progress_bar.empty()
        status_text.empty()
        return results
        
    except HttpError as e:
        st.error(f"YouTube API ì˜¤ë¥˜: {e}")
        return []
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def upload_to_sheets(creds_file, sheet_url, data_list, category, subcategory, type_text, sheet_name="source_urls"):
    """Google Sheets ì—…ë¡œë“œ"""
    try:
        scope = ['https://spreadsheets.google.com/feeds',
                'https://www.googleapis.com/auth/drive']
        
        creds = Credentials.from_service_account_file(creds_file, scopes=scope)
        client = gspread.authorize(creds)
        
        # ì‹œíŠ¸ ì—´ê¸°
        try:
            sheet = client.open_by_url(sheet_url).worksheet(sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            st.error(f"'{sheet_name}' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 0, 0
            
        # ê¸°ì¡´ ë°ì´í„° ì½ê¸°
        existing_data = sheet.get_all_values()
        
        # í—¤ë” ì²˜ë¦¬
        headers = []
        if existing_data:
            headers = existing_data[0]
        else:
            # í—¤ë”ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ í—¤ë” ìƒì„± ë° ì¶”ê°€
            headers = ['URL', 'title', 'category', 'subcategory', 'type', 'processed', 'processed_date', 'result_index']
            sheet.append_row(headers)
            existing_data = [headers]
            
        # í—¤ë” ë§¤í•‘ (ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ì¸ë±ìŠ¤ ì €ì¥)
        header_map = {h.lower().strip(): i for i, h in enumerate(headers)}
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì°¾ê¸°
        url_idx = -1
        index_idx = -1
        
        # URL ì»¬ëŸ¼ ì°¾ê¸° (url, link, ì£¼ì†Œ ë“±)
        for key in ['url', 'link', 'ì£¼ì†Œ']:
            if key in header_map:
                url_idx = header_map[key]
                break
                
        # Index ì»¬ëŸ¼ ì°¾ê¸° (result_index, index, ì¸ë±ìŠ¤ ë“±)
        for key in ['result_index', 'index', 'ì¸ë±ìŠ¤']:
            if key in header_map:
                index_idx = header_map[key]
                break
        
        existing_urls = set()
        max_index = 0
        
        # ê¸°ì¡´ ë°ì´í„° ë¶„ì„ (ì¤‘ë³µ ì²´í¬ ë° Max Index)
        if len(existing_data) > 1:
            for row in existing_data[1:]: # í—¤ë” ì œì™¸
                if not row: continue
                
                # URL ìˆ˜ì§‘
                if url_idx != -1 and len(row) > url_idx:
                    existing_urls.add(row[url_idx])
                elif url_idx == -1 and len(row) > 0: # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ê°€ì •
                    existing_urls.add(row[0])
                    
                # Max Index ê³„ì‚°
                if index_idx != -1 and len(row) > index_idx:
                    val = row[index_idx]
                    if val.isdigit():
                        max_index = max(max_index, int(val))
                elif index_idx == -1 and len(row) > 6: # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ 7ë²ˆì§¸(ì¸ë±ìŠ¤ 6) ì»¬ëŸ¼ ê°€ì • (ê¸°ì¡´ ë¡œì§ í˜¸í™˜)
                    val = row[6]
                    if val.isdigit():
                        max_index = max(max_index, int(val))
        
        # ë°ì´í„° ì¤€ë¹„
        rows_to_append = []
        duplicate_count = 0
        current_index = max_index + 1
        
        for data in data_list:
            if data['url'] in existing_urls:
                duplicate_count += 1
                continue
            
            # í—¤ë”ì— ë§ì¶° í–‰ ë°ì´í„° ìƒì„± (ê¸°ë³¸ê°’ ë¹ˆ ë¬¸ìì—´)
            row = [''] * len(headers)
            
            def set_col(keys, value):
                for key in keys:
                    if key.lower() in header_map:
                        row[header_map[key.lower()]] = str(value)
                        return
            
            # ë°ì´í„° ë§¤í•‘
            set_col(['url', 'link', 'ì£¼ì†Œ'], data['url'])
            set_col(['title', 'ì œëª©'], data['title'])
            set_col(['category', 'ì¹´í…Œê³ ë¦¬'], category)
            set_col(['subcategory', 'ì„œë¸Œì¹´í…Œê³ ë¦¬'], subcategory)
            set_col(['type', 'ìœ í˜•', 'post_type'], type_text)
            set_col(['processed', 'ì²˜ë¦¬ì—¬ë¶€', 'posted'], 'âœ“')
            set_col(['processed_date', 'ì²˜ë¦¬ì¼', 'posted_date', 'posted_time'], datetime.now().strftime('%Y-%m-%d'))
            set_col(['result_index', 'index', 'ì¸ë±ìŠ¤'], str(current_index))
            
            # ë§¤í•‘ë˜ì§€ ì•Šì€ í•„ìˆ˜ ë°ì´í„° ì²˜ë¦¬ (í—¤ë”ê°€ ì—†ê±°ë‚˜ ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìœ„ì¹˜ì— í• ë‹¹ ì‹œë„)
            # ì£¼ì˜: ë™ì  ë§¤í•‘ì„ ì‚¬ìš©í•˜ë¯€ë¡œ, í—¤ë”ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ë°ì´í„°ê°€ ëˆ„ë½ë  ìˆ˜ ìˆìŒ.
            # í˜¸í™˜ì„±ì„ ìœ„í•´ URLì´ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì²« ë²ˆì§¸ì— ë„£ëŠ” ë“±ì˜ ì²˜ë¦¬ëŠ” í•˜ì§€ ì•ŠìŒ (í—¤ë”ê°€ ìˆì„ ê²ƒì´ë¼ ê°€ì •)
            
            rows_to_append.append(row)
            current_index += 1
            
        if rows_to_append:
            sheet.append_rows(rows_to_append)
            
        return len(rows_to_append), duplicate_count
        
    except Exception as e:
        st.error(f"ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 0, 0

def run_self_test(api_key, creds_file, sheet_url, sheet_name="source_urls"):
    """ì„¤ì • ìê°€ ì§„ë‹¨ ì‹¤í–‰"""
    results = []
    
    # 1. YouTube API í…ŒìŠ¤íŠ¸
    try:
        if not api_key:
            results.append(("âŒ", "YouTube API: í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."))
        else:
            youtube = build("youtube", "v3", developerKey=api_key)
            youtube.search().list(q="test", part="id", maxResults=1).execute()
            results.append(("âœ…", "YouTube API: ì—°ê²° ì„±ê³µ"))
    except HttpError as e:
        results.append(("âŒ", f"YouTube API: ì˜¤ë¥˜ ({e.resp.status}) - {e.content.decode('utf-8')}"))
    except Exception as e:
        results.append(("âŒ", f"YouTube API: ì˜¤ë¥˜ - {str(e)}"))
        
    # 2. Google Sheets ì¸ì¦ íŒŒì¼ í…ŒìŠ¤íŠ¸
    creds = None
    try:
        if not creds_file or creds_file == "íŒŒì¼ ì—†ìŒ":
            results.append(("âŒ", "Google Sheets: ì¸ì¦ íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."))
        elif not os.path.exists(creds_file):
            results.append(("âŒ", f"Google Sheets: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ ({creds_file})"))
        else:
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            creds = Credentials.from_service_account_file(creds_file, scopes=scope)
            results.append(("âœ…", "Google Sheets: ì¸ì¦ íŒŒì¼ ë¡œë“œ ì„±ê³µ"))
    except Exception as e:
        results.append(("âŒ", f"Google Sheets: ì¸ì¦ íŒŒì¼ ì˜¤ë¥˜ - {str(e)}"))
        
    # 3. Spreadsheet ì ‘ê·¼ í…ŒìŠ¤íŠ¸
    if creds and sheet_url:
        try:
            client = gspread.authorize(creds)
            sheet = client.open_by_url(sheet_url)
            try:
                sheet.worksheet(sheet_name)
                results.append(("âœ…", f"Google Sheets: '{sheet_name}' ì‹œíŠ¸ í™•ì¸ë¨"))
            except gspread.exceptions.WorksheetNotFound:
                results.append(("âš ï¸", f"Google Sheets: '{sheet_name}' ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."))
        except Exception as e:
            results.append(("âŒ", f"Google Sheets: ì ‘ê·¼ ì‹¤íŒ¨ - {str(e)}"))
    elif not sheet_url:
        results.append(("âš ï¸", "Google Sheets: URLì´ ì…ë ¥ë˜ì§€ ì•Šì•„ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."))
        
    return results


def update_card_selection(idx):
    """ì¹´ë“œ ë·°ì—ì„œ ì²´í¬ë°•ìŠ¤ ë³€ê²½ ì‹œ DataFrame ì—…ë°ì´íŠ¸"""
    st.session_state.search_results.at[idx, 'selected'] = st.session_state[f"card_chk_{idx}"]

# === UI Layout ===

st.title("YouTube URL ìˆ˜ì§‘ê¸° ğŸ“º")

# --- Sidebar ---
with st.sidebar:
    st.header("ì„¤ì •")
    
    # API Key
    api_key = st.text_input("YouTube API Key", value=load_api_key(), type="password")
    
    # Group 1: Search Settings
    st.header("1. ê²€ìƒ‰ ì„¤ì •")
    keyword = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", value=st.session_state.get('keyword', "íŒŒì´ì¬ ê°•ì˜"))
    max_results = st.number_input("ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼", min_value=10, max_value=100, value=st.session_state.get('max_results', 50))
    
    # Date Range
    period_option = st.selectbox("ê²€ìƒ‰ ê¸°ê°„", ["ì „ì²´ ê¸°ê°„", "ìµœê·¼ 7ì¼", "ìµœê·¼ 15ì¼", "ìµœê·¼ 30ì¼", "ì§ì ‘ ì…ë ¥"], index=["ì „ì²´ ê¸°ê°„", "ìµœê·¼ 7ì¼", "ìµœê·¼ 15ì¼", "ìµœê·¼ 30ì¼", "ì§ì ‘ ì…ë ¥"].index(st.session_state.get('period_option', "ì „ì²´ ê¸°ê°„")))
    
    published_after = None
    published_before = None
    today = datetime.now()
    
    if period_option == "ìµœê·¼ 7ì¼":
        published_after = (today - timedelta(days=7)).strftime("%Y-%m-%dT00:00:00Z")
    elif period_option == "ìµœê·¼ 15ì¼":
        published_after = (today - timedelta(days=15)).strftime("%Y-%m-%dT00:00:00Z")
    elif period_option == "ìµœê·¼ 30ì¼":
        published_after = (today - timedelta(days=30)).strftime("%Y-%m-%dT00:00:00Z")
    elif period_option == "ì§ì ‘ ì…ë ¥":
        col1, col2 = st.columns(2)
        start_date = col1.date_input("ì‹œì‘ì¼", today - timedelta(days=7))
        end_date = col2.date_input("ì¢…ë£Œì¼", today)
        published_after = start_date.strftime("%Y-%m-%dT00:00:00Z")
        published_before = (end_date + timedelta(days=1)).strftime("%Y-%m-%dT00:00:00Z")

    # ê²€ìƒ‰ ë²„íŠ¼ (ì‚¬ì´ë“œë°”)
    if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary"):
        if not api_key:
            st.warning("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not keyword:
            st.warning("ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            # ê²€ìƒ‰ ë¡œì§ì€ ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‹¤í–‰ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥í•˜ê±°ë‚˜
            # ì—¬ê¸°ì„œ ë°”ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
            # (ê¸°ì¡´ ë¡œì§ì´ ì‚¬ì´ë“œë°” ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰ë˜ë¯€ë¡œ êµ¬ì¡° ìœ ì§€)
            st.session_state.trigger_search = True

    st.divider()
    
    st.divider()
    
    # Self Test ë° Upload Settingsë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ (ë Œë”ë§ ìˆœì„œ ì œì–´)
    # ë©”ì¸ ì»¨í…ì¸ ì—ì„œ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ëœ í›„ ë‚´ìš©ì„ ì±„ìš°ê¸° ìœ„í•´ ë¹ˆ ì»¨í…Œì´ë„ˆë§Œ ë¯¸ë¦¬ ìƒì„±
    self_test_container = st.container()
    upload_settings_container = st.container()




# --- Main Content ---

# (Session State ì´ˆê¸°í™”ëŠ” ìƒë‹¨ìœ¼ë¡œ ì´ë™ë¨)

# ê²€ìƒ‰ ë¡œì§ ì‹¤í–‰
if st.session_state.get('trigger_search', False):
    st.session_state.trigger_search = False # Reset trigger
    results = search_youtube(api_key, keyword, max_results, published_after, published_before)
    if results:
        st.session_state.search_results = pd.DataFrame(results)
        
        # ê²€ìƒ‰ ì„±ê³µ ì‹œ ìƒíƒœ ì €ì¥
        state_to_save = {
            'search_results': st.session_state.search_results,
            'keyword': keyword,
            'max_results': max_results,
            'period_option': period_option,
            'sheet_name': st.session_state.get('sheet_name', "source_urls"),
            # í•„ìš”í•œ ë‹¤ë¥¸ ì„¤ì •ê°’ë“¤ë„ ì €ì¥ ê°€ëŠ¥
        }
        save_state(state_to_save)
        
        st.success(f"{len(results)}ê°œì˜ ì˜ìƒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ê²°ê³¼ í‘œì‹œ ë° ì„ íƒ
if not st.session_state.search_results.empty:
    st.divider()
    
    # ë·° ëª¨ë“œ ì„ íƒ
    col_view, col_action = st.columns([1, 4])
    with col_view:
        view_mode = st.radio("ë³´ê¸° ëª¨ë“œ", ["ë¦¬ìŠ¤íŠ¸", "ì¹´ë“œ"], horizontal=True, label_visibility="collapsed")
    
    # ì „ì²´ ì„ íƒ/í•´ì œ ë²„íŠ¼
    with col_action:
        sub_c1, sub_c2, _ = st.columns([1, 1, 4])
        if sub_c1.button("ì „ì²´ ì„ íƒ"):
            st.session_state.search_results['selected'] = True
            st.rerun()
        if sub_c2.button("ì „ì²´ í•´ì œ"):
            st.session_state.search_results['selected'] = False
            st.rerun()
        
    if view_mode == "ë¦¬ìŠ¤íŠ¸":
        # ë°ì´í„° ì—ë””í„° (í…Œì´ë¸”)
        edited_df = st.data_editor(
            st.session_state.search_results,
            column_config={
                "selected": st.column_config.CheckboxColumn(
                    "ì„ íƒ",
                    help="ì—…ë¡œë“œí•  ì˜ìƒì„ ì„ íƒí•˜ì„¸ìš”",
                    default=False,
                ),
                "thumbnail": st.column_config.ImageColumn(
                    "ì¸ë„¤ì¼", help="ì˜ìƒ ì¸ë„¤ì¼"
                ),
                "url": st.column_config.LinkColumn(
                    "URL", help="ì˜ìƒ ë§í¬"
                ),
                "view_count": st.column_config.NumberColumn(
                    "ì¡°íšŒìˆ˜", format="%d"
                ),
                "subscriber_count": st.column_config.NumberColumn(
                    "êµ¬ë…ììˆ˜", format="%d"
                ),
                "comment_count": st.column_config.NumberColumn(
                    "ëŒ“ê¸€ìˆ˜", format="%d"
                ),
                "view_sub_ratio": st.column_config.NumberColumn(
                    "ì¡°íšŒ/êµ¬ë… ë¹„ìœ¨", format="%.4f", help="ì˜ìƒ ì¡°íšŒìˆ˜ / êµ¬ë…ììˆ˜"
                ),
                "view_diff": st.column_config.NumberColumn(
                    "ì¡°íšŒìˆ˜ ì°¨ì´", format="%d", help="ì¡°íšŒìˆ˜ - ì±„ë„ í‰ê·  ì¡°íšŒìˆ˜"
                ),
            },
            disabled=["thumbnail", "url", "title", "channel", "view_count", "subscriber_count", "comment_count", "published_at", "view_sub_ratio", "view_diff"],
            hide_index=True,
            width='stretch',
            height=600
        )
        # ìƒíƒœ ì—…ë°ì´íŠ¸ (ì‚¬ìš©ì ì„ íƒ ë°˜ì˜)
        st.session_state.search_results = edited_df
        
    else: # ì¹´ë“œ ë³´ê¸°
        # ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒ (4ì—´)
        cols = st.columns(4)
        for idx, row in st.session_state.search_results.iterrows():
            with cols[idx % 4]:
                with st.container(border=True):
                    # ì¸ë„¤ì¼
                    st.image(row['thumbnail'], width='stretch')
                    
                    # ì œëª© (ë§í¬ í¬í•¨)
                    st.markdown(f"**[{row['title']}]({row['url']})**")
                    
                    # ì±„ë„ ë° í†µê³„
                    st.caption(f"{row['channel']}")
                    st.caption(f"ğŸ‘ï¸ {row['view_count']:,} | ğŸ’¬ {row['comment_count']:,}")
                    st.caption(f"Ratio: {row['view_sub_ratio']:.4f} | Diff: {row['view_diff']:,.0f}")
                    
                    # ì„ íƒ ì²´í¬ë°•ìŠ¤
                    st.checkbox(
                        "ì„ íƒ", 
                        value=row['selected'], 
                        key=f"card_chk_{idx}",
                        on_change=update_card_selection,
                        args=(idx,)
                    )
    
    edited_df = st.session_state.search_results # ì¹´ë“œ ë·°ì—ì„œë„ edited_df ì°¸ì¡°ë¥¼ ìœ„í•´
    
    # ì„ íƒëœ í•­ëª© ìˆ˜ í‘œì‹œ
    selected_rows = edited_df[edited_df['selected']]
    st.write(f"ì„ íƒëœ í•­ëª©: {len(selected_rows)}ê°œ")
    
    st.divider()

    # (Self TestëŠ” ì‚¬ì´ë“œë°”ë¡œ ì´ë™ë¨)

    
    st.divider()

# --- Sidebar Content Filling (After Main Content Update) ---
# ë©”ì¸ ì»¨í…ì¸ (st.data_editor ë“±)ê°€ ì‹¤í–‰ëœ í›„ ì—…ë°ì´íŠ¸ëœ session_stateë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì´ë“œë°” ë Œë”ë§

# 1. Upload Settings ë Œë”ë§
# ê¸°ë³¸ê°’ ì„¤ì •
selected_creds = "íŒŒì¼ ì—†ìŒ"
sheet_url = load_config_url()
sheet_name = st.session_state.get('sheet_name', "source_urls")

# ê²€ìƒ‰ ê²°ê³¼ ë° ì„ íƒ í•­ëª© í™•ì¸
has_results = not st.session_state.search_results.empty
has_selection = False
if has_results and 'selected' in st.session_state.search_results.columns:
    has_selection = st.session_state.search_results['selected'].any()

with upload_settings_container:
    if has_selection:
        st.divider()
        st.header("2. ì—…ë¡œë“œ ì„¤ì •")
        
        # Category Settings
        st.subheader("ì¹´í…Œê³ ë¦¬")
        category = st.text_input("Category", "ë””ì§€í„¸ ê°€ì „")
        subcategory = st.text_input("Subcategory", keyword) # ê¸°ë³¸ê°’ì„ ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ì„¤ì •
        post_type = st.selectbox("Type", ['ì¤‘ê²©ì •ë³´í˜•', 'ë¹„êµë¶„ì„í˜•', 'ê¿€íŒê³µìœ í˜•', 'ì •ë³´ê³µìœ í˜•'])
        
        # Google Sheets Settings
        st.subheader("Google Sheets")
        creds_files = get_credentials_files()
        selected_creds = st.selectbox("ì¸ì¦ íŒŒì¼", creds_files if creds_files else ["íŒŒì¼ ì—†ìŒ"])
        sheet_url = st.text_input("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URL", value=sheet_url)
        sheet_name = st.text_input("ì‹œíŠ¸ ì´ë¦„", value=sheet_name)
        
        st.divider()
        
        # ì„ íƒëœ í•­ëª© ê³„ì‚°
        selected_rows = st.session_state.search_results[st.session_state.search_results['selected']]
        
        if st.button("ğŸ“¤ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì—…ë¡œë“œ", type="primary", disabled=len(selected_rows) == 0):
            if not selected_creds or selected_creds == "íŒŒì¼ ì—†ìŒ":
                st.error("ì¸ì¦ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            elif not sheet_url:
                st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                creds_path = os.path.join(os.getcwd(), 'credentials', selected_creds)
                
                # DataFrameì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                data_to_upload = selected_rows.to_dict('records')
                
                with st.spinner("ì—…ë¡œë“œ ì¤‘..."):
                    success_count, duplicate_count = upload_to_sheets(
                        creds_path, 
                        sheet_url, 
                        data_to_upload, 
                        category, 
                        subcategory, 
                        post_type,
                        sheet_name
                    )
                    
                if success_count > 0:
                    st.balloons()
                    msg = f"{success_count}ê°œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!"
                    if duplicate_count > 0:
                        msg += f" ({duplicate_count}ê°œ ì¤‘ë³µ ì œì™¸)"
                    st.success(msg)
                elif duplicate_count > 0:
                    st.warning(f"ì—…ë¡œë“œí•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. (ì„ íƒëœ {duplicate_count}ê°œ ëª¨ë‘ ì´ë¯¸ ì¡´ì¬í•¨)")
                else:
                    st.error("ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ì¶”ê°€í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

# 2. Self Test ë Œë”ë§ (Upload Settingsì—ì„œ ì„¤ì •ëœ ë³€ìˆ˜ ì‚¬ìš© ê°€ëŠ¥)
with self_test_container:
    with st.expander("ğŸ› ï¸ ì„¤ì • ë° ì§„ë‹¨"):
        if st.button("ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
            creds_path = os.path.join(os.getcwd(), 'credentials', selected_creds) if selected_creds != "íŒŒì¼ ì—†ìŒ" else None
            test_results = run_self_test(api_key, creds_path, sheet_url, sheet_name)
            
            for icon, msg in test_results:
                if icon == "âœ…":
                    st.success(f"{icon} {msg}")
                elif icon == "âš ï¸":
                    st.warning(f"{icon} {msg}")
                else:
                    st.error(f"{icon} {msg}")
